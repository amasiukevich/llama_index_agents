{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import (\n",
    "    COMPLETIONS_MODEL,\n",
    "    API_EXCHANGE_VERSION,\n",
    "    API_BASE_URL,\n",
    "    \n",
    "    EMBEDDINGS_MODEL,\n",
    "    EMBEDDINGS_BASE_URL,\n",
    "    TOKEN_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def add(x: int, y: int):\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int):\n",
    "    \"\"\"Mystery fucntion that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x - y)\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    engine=COMPLETIONS_MODEL,\n",
    "    api_key=TOKEN_ID,\n",
    "    api_version=API_EXCHANGE_VERSION,\n",
    "    azure_endpoint=f\"{API_BASE_URL}/api\",\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    engine=EMBEDDINGS_MODEL,\n",
    "    api_key=TOKEN_ID,\n",
    "    api_version=API_EXCHANGE_VERSION,\n",
    "    azure_endpoint=f\"{EMBEDDINGS_BASE_URL}/api\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: add with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool],\n",
    "    \"Tell me the output of the add function on 2 and 9\",\n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an Auto-Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# loading documents\n",
    "documents = SimpleDirectoryReader(input_files=['data/metagpt.pdf']).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 3\n",
      "file_name: metagpt.pdf\n",
      "file_path: data\\metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-05-31\n",
      "last_modified_date: 2024-05-31\n",
      "\n",
      "Other works focus on\n",
      "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
      "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
      "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
      "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
      "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
      "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
      "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
      "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
      "agents frameworks. Besides, LLM-based agents face the challenges of “assistant repeated instruc-\n",
      "tion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\n",
      "become more urgent in task-oriented collaborations, which require consistent and mutually benefi-\n",
      "cial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\n",
      "on applying advanced concepts such as Standard Operating Procedures in software development to\n",
      "multi-agent frameworks.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(nodes[3].get_content(metadata_mode='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [{'key': 'page_label', 'value': '2'}]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are some high-level results of MetaGPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MetaGPT achieves a new state-of-the-art (SoTA) in code generation benchmarks with 85.9% and 87.7% in Pass@1. It also stands out in handling higher levels of software complexity and offering extensive functionality. In experimental evaluations, MetaGPT achieves a 100% task completion rate, demonstrating the robustness and efficiency (time and token costs) of its design.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'data\\\\metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhansing Data Retrieval\n",
    "\n",
    "- Integrating Metadata Filters into a retrieval tool function\n",
    "\n",
    "- This function enables more precise retrieval by accepting a query string and optional metadata filters, such as page numbers\n",
    "\n",
    "- The LLM can intelligently infer relevant metadata filters (e.g. page numbers) based on user's query\n",
    "  \n",
    "- We can define different types of metadata filters like section IDs, headers or footers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "def vector_query(query: str, page_numbers: List[int]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs a vector search over an index.\n",
    "    \n",
    "    query str: string query to be embedded\n",
    "    page numbers List[int]: Filter by set of pages. Leave BLANK if we want to query over all pages.\n",
    "                            Otherwise filter by set of specific pages.\n",
    "    \"\"\"\n",
    "    \n",
    "    metadata_dicts = [\n",
    "        {'key': 'page_label', 'value': str(p)} for p in page_numbers\n",
    "    ]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    response = query_engine.query(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"benchmark results MetaGPT\", \"page_numbers\": [2]}\n",
      "=== Function Output ===\n",
      "MetaGPT achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1 in code generation benchmarks, outperforming other popular frameworks for creating complex software projects such as AutoGPT, LangChain, AgentVerse, and ChatDev. Additionally, MetaGPT stands out in handling higher levels of software complexity and offering extensive functionality, as demonstrated by its 100% task completion rate in experimental evaluations.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool],\n",
    "    \"What are the benchmark results of MetaGPT as described on page 2?\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'data\\\\metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up all the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True\n",
    ")\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of MetaGPT\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"MetaGPT comparisons with ChatDev\", \"page_numbers\": [8]}\n",
      "=== Function Output ===\n",
      "MetaGPT outperforms ChatDev on the challenging SoftwareDev dataset in nearly all metrics, according to Table 1 in the provided context. For example, considering the executability, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Additionally, MetaGPT takes less time (503 seconds) compared to ChatDev. Considering the code statistic and the cost of human revision, MetaGPT also significantly outperforms ChatDev.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool],\n",
    "    \"what are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
